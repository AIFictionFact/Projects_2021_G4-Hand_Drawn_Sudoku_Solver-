{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SudokuTrainer.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RFcR0oM92bL"
      },
      "source": [
        "# Train model on MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZyvTUHw6VCL",
        "outputId": "a7ef5ab1-dcc2-4f00-db58-79a33a7e12c3"
      },
      "source": [
        "import uuid\n",
        "import shutil\n",
        "import numpy as np\n",
        "import cv2\n",
        "import math\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from imutils.perspective import four_point_transform\n",
        "import imutils\n",
        "from google.colab.patches import cv2_imshow\n",
        "from scipy.optimize import minimize_scalar\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKV-U85v6m40",
        "outputId": "1b00c02f-1931-40ea-e9ac-2604505aedb0"
      },
      "source": [
        "!pip install np_utils\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: np_utils in /usr/local/lib/python3.7/dist-packages (0.5.12.1)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from np_utils) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from np_utils) (1.19.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0Y22ICM7B8r"
      },
      "source": [
        "# Use the following line to install the torchvision library, if it is not already installed\n",
        "# !conda install -y torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import matplotlib.pylab as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions import normal\n",
        "import time\n",
        "\n",
        "import glob\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApP_HLL36Zma",
        "outputId": "4aa1455e-e879-467c-c85d-127ae3ade347"
      },
      "source": [
        "# Create and print the training dataset\n",
        "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "print(\"Print the training dataset:\\n \", train_dataset)\n",
        "\n",
        "# Create and print the validating dataset\n",
        "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "print(\"Print the validating dataset:\\n \", validation_dataset)\n",
        "\n",
        "# Print the label\n",
        "print(\"The label: \", train_dataset[3][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Print the training dataset:\n",
            "  Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "Print the validating dataset:\n",
            "  Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "The label:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Ab0hSn6bvD"
      },
      "source": [
        "IMAGE_SIZE = 28\n",
        "\n",
        "composed = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor()])\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=composed)\n",
        "\n",
        "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=composed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oavN8-IA6dA_"
      },
      "source": [
        "def show_data(data_sample):\n",
        "    plt.imshow(data_sample[0].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n",
        "    plt.title('y = '+ str(data_sample[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXJr2JrG6eQO",
        "outputId": "6b519ba6-dd0d-4482-e56d-740d9c2a39ad"
      },
      "source": [
        "# The label for the fourth data element\n",
        "train_dataset[3][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "d8mot7fi6for",
        "outputId": "81e454a4-b9bf-4c99-9bc5-83f93e04836f"
      },
      "source": [
        "show_data(train_dataset[3])\n",
        "print(train_dataset[3][0].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgKLR8Pu6kvZ"
      },
      "source": [
        "\n",
        "# the MNIST data is split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NbMPcpS6qNb"
      },
      "source": [
        "# Reshape to be samples*pixels*width*height\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# One hot Cpde\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "# convert from integers to floats\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# normalize to range [0, 1]\n",
        "X_train = (X_train / 255.0)\n",
        "X_test = (X_test / 255.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e5bvh6Y6r-P",
        "outputId": "8971a976-f69f-4b91-a328-7fccbeba1230"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 9, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               102500    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 159,254\n",
            "Trainable params: 159,254\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVjnsv7C6tW-"
      },
      "source": [
        "def evaluate_model(X_train, y_Train, n_folds=5):\n",
        "    accuracy, data = list(), list()\n",
        "    # prepare 5-cross validation\n",
        "    kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
        "\n",
        "    for x_train, x_test in kfold.split(X_train):\n",
        "        # create model\n",
        "        model = create_model()\n",
        "        # select rows for train and test\n",
        "        trainX, trainY, testX, testY = X_train[x_train], y_Train[x_train], X_train[x_test], y_Train[x_test]\n",
        "        # fit model\n",
        "        data_fit = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=10, batch_size=32)\n",
        "        # evaluate model\n",
        "        _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "        # stores Accuracy \n",
        "        accuracy.append(acc)\n",
        "        data.append(data_fit)\n",
        "    return accuracy, data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmfmI2qv6upN"
      },
      "source": [
        "# summarize model performance\n",
        "def summarize_performance(acc):\n",
        "    # print summary\n",
        "    print('Accuracy: mean=%.3f std=%.3f, n=%d' % (numpy.mean(acc) * 100, numpy.std(acc) * 100, len(acc)))\n",
        "\n",
        "    # box and whisker plots of results\n",
        "    pyplot.boxplot(acc)\n",
        "    pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "7wKdPFvE6wBd",
        "outputId": "cc3c5bda-0d67-48f5-8408-0a4657367b09"
      },
      "source": [
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " 3000/60000 [>.............................] - ETA: 1:02 - loss: 1.2599 - accuracy: 0.6047"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c4691c1e7982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compile model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}